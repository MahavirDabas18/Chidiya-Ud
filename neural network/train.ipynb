{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1944f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import random\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dropout, Dense, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a044f4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab156697",
   "metadata": {},
   "source": [
    "<h1> Preparing the Dataset </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "117ba0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder_path,folder_name):\n",
    "    '''#reads all images in a folder and returns a list of arrays'''\n",
    "    images = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        img = cv2.imread(os.path.join(folder_path,filename))\n",
    "        #converting colour space from BGR TO RGB- opencv reads in bgr format\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        #resizing the image size-original image size captured by us was 400*400\n",
    "        img = cv2.resize(img, (224, 224))\n",
    "        img=img/255.0 #normalizing pixel values between 0 and 1\n",
    "        data_point=[]\n",
    "        data_point.append(img) #appending the image array\n",
    "        data_point.append(folder_name) #appending the image class\n",
    "        if img is not None:\n",
    "            images.append(data_point)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37f9adcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path=\"images\"\n",
    "dataset=[]\n",
    "for directory in os.listdir(img_path):\n",
    "    folder_path = os.path.join(img_path, directory) #getting a particular folder\n",
    "    image_folder=load_images_from_folder(folder_path, directory)\n",
    "    dataset=dataset+image_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f561028a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = [ [[...], 'rock'],\n",
    "#[[...], 'paper'],\n",
    "#...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89ae2414",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4f0e1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = zip(*dataset) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2a56393",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapping categories to numbers\n",
    "class_map = {\n",
    "    \"flap\": 0,\n",
    "    \"none\": 1,\n",
    "    \"quit\": 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7783e4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapper(val):\n",
    "    return class_map[val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2e5c79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting labels to numbers\n",
    "y=list(map(mapper, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5a50d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting labels to one hot encoded vectors\n",
    "y=to_categorical(y, dtype =\"uint8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02014a12",
   "metadata": {},
   "source": [
    "<h1> Train Test Split </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e8a1195",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split-90-10 split\n",
    "split_index=int(len(dataset)*0.9)\n",
    "x_train=x[0:split_index]\n",
    "y_train=y[0:split_index]\n",
    "\n",
    "x_test=x[split_index:]\n",
    "y_test=y[split_index:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9e25c6",
   "metadata": {},
   "source": [
    "<h1> Creating the Model </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b976dcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the the model\n",
    "def get_model():\n",
    "    model=Sequential()\n",
    "    \n",
    "    #defining the base model\n",
    "    base_model = MobileNet(\n",
    "    weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(224, 224, 3),\n",
    "    classes=3,\n",
    "    pooling='avg',\n",
    "    include_top=False)  # Do not include the ImageNet classifier i/p and o/p layer\n",
    "    \n",
    "    #freeezing the weights of the final layer \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable=False\n",
    "        \n",
    "    model.add(base_model)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512,activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(3,activation='softmax')) #final op layer\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce6df22",
   "metadata": {},
   "source": [
    "<h1> Compiling the Model </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32a62215",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compiling the model\n",
    "model = get_model()\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.01),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61457280",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenet_1.00_224 (Function (None, 1024)              3228864   \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 3,755,203\n",
      "Trainable params: 526,339\n",
      "Non-trainable params: 3,228,864\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a91f48e",
   "metadata": {},
   "source": [
    "<h1> Training the Model </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d50cea28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "85/85 [==============================] - 21s 110ms/step - loss: 0.9694 - accuracy: 0.9081 - val_loss: 0.0182 - val_accuracy: 0.9967\n",
      "Epoch 2/10\n",
      "85/85 [==============================] - 7s 87ms/step - loss: 0.0237 - accuracy: 0.9930 - val_loss: 0.0052 - val_accuracy: 0.9967\n",
      "Epoch 3/10\n",
      "85/85 [==============================] - 7s 88ms/step - loss: 0.0138 - accuracy: 0.9970 - val_loss: 0.0061 - val_accuracy: 0.9933\n",
      "Epoch 4/10\n",
      "85/85 [==============================] - 7s 86ms/step - loss: 0.0133 - accuracy: 0.9970 - val_loss: 0.0060 - val_accuracy: 0.9967\n",
      "Epoch 5/10\n",
      "85/85 [==============================] - 7s 87ms/step - loss: 0.0134 - accuracy: 0.9956 - val_loss: 0.0119 - val_accuracy: 0.9967\n",
      "Epoch 6/10\n",
      "85/85 [==============================] - 7s 87ms/step - loss: 0.0091 - accuracy: 0.9948 - val_loss: 0.0130 - val_accuracy: 0.9933\n",
      "Epoch 7/10\n",
      "85/85 [==============================] - 8s 89ms/step - loss: 0.1315 - accuracy: 0.9719 - val_loss: 0.0335 - val_accuracy: 0.9967\n",
      "Epoch 8/10\n",
      "85/85 [==============================] - 8s 88ms/step - loss: 0.1185 - accuracy: 0.9826 - val_loss: 0.0110 - val_accuracy: 0.9967\n",
      "Epoch 9/10\n",
      "85/85 [==============================] - 8s 89ms/step - loss: 0.0701 - accuracy: 0.9822 - val_loss: 0.0061 - val_accuracy: 0.9967\n",
      "Epoch 10/10\n",
      "85/85 [==============================] - 7s 88ms/step - loss: 0.0139 - accuracy: 0.9952 - val_loss: 0.0056 - val_accuracy: 0.9967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2685b018d30>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=np.array(x_train),y=np.array(y_train), batch_size=32, \n",
    "          validation_data=(np.array(x_test),np.array(y_test)),\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae48e55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13738331",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ed5eca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d5834d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33e1ef7e",
   "metadata": {},
   "source": [
    "<h1> Saving the Trained Model </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e6c8e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88b9ef4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/model_t\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/model_t\\assets\n"
     ]
    }
   ],
   "source": [
    "! mkdir -p saved_model\n",
    "model.save('saved_model/model_t') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b727b49c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e99969",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
